{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tietojenkäsittelytieteen opastus VS Code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Osa 1. Esivaatimukset:\n",
    "- Visual Studio Code\n",
    "- Laajennukset:\n",
    "    - Python extension for VS Code\n",
    "    - Jupyter extension for VS Code\n",
    "- Miniconda tai Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Osa 2. Määritä data science ympäristö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asennus\n",
    "\n",
    "1. Kloonaa repositorio:\n",
    "\n",
    "        git clone https://github.com/yourusername/yourproject.git\n",
    "\n",
    "2. Siirry projektin hakemistoon:\n",
    "\n",
    "        cd data-science-tutorial\n",
    "   \n",
    "3. Määritä Conda-ympäristö käyttämällä tämän reposta löytyvää yml-tiedostoa:\n",
    "\n",
    "        conda env create -f environment.yml\n",
    "\n",
    "4. Aktivoi ympäristö:\n",
    "\n",
    "        conda activate myenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Osa 3. Valmistele data\n",
    "\n",
    "- Käsittele ja puhdista data\n",
    "- Tarkista korrelaatiot\n",
    "- Valmistelun jälkeen sinulla on datasetti, jota voidaan käyttää mallin kouluttamiseen\n",
    "   - tässä tapauksessa valitsimme seuraavat muuttujat: 'sex', 'pclass', 'age', 'relatives', 'fare', 'survived'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('titanic3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, figsize=(30,5))\n",
    "sns.violinplot(x=\"survived\", y=\"age\", hue=\"sex\", data=data, ax=axs[0])\n",
    "sns.pointplot(x=\"sibsp\", y=\"survived\", hue=\"sex\", data=data, ax=axs[1])\n",
    "sns.pointplot(x=\"parch\", y=\"survived\", hue=\"sex\", data=data, ax=axs[2])\n",
    "sns.pointplot(x=\"pclass\", y=\"survived\", hue=\"sex\", data=data, ax=axs[3])\n",
    "sns.violinplot(x=\"survived\", y=\"fare\", hue=\"sex\", data=data, ax=axs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({'male': 1, 'female': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr(numeric_only=True).abs()[[\"survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relatives'] = data.apply (lambda row: int((row['sibsp'] + row['parch']) > 0), axis=1)\n",
    "corr_with_survived = data.corr(numeric_only=True).abs()[[\"survived\"]]\n",
    "print(corr_with_survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if you want to choose specific columns for example to skip body that is not needed.\n",
    "'''\n",
    "data['relatives'] = data.apply (lambda row: int((row['sibsp'] + row['parch']) > 0), axis=1)\n",
    "\n",
    "columns_to_check = ['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'relatives']\n",
    "\n",
    "corr_matrix = data[columns_to_check].corr()\n",
    "\n",
    "corr_with_survived = corr_matrix[['survived']].abs()\n",
    "\n",
    "print(corr_with_survived)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['sex', 'pclass','age','relatives','fare','survived']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: use this to run the python file version.\n",
    "\n",
    "# %run script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Osa 4. Kouluta ja arvioi malli\n",
    "   Tässä osiossa käytä scikit-learn-kirjastoa (se tarjoaa hyödyllisiä apufunktioita) datasetin käsittelyyn, luokitellaksesi mallin, joka ennustaa selviytymistä laivalla. Käytä sen jälkeen mallia testidatan kanssa arvioidaksesi sen tarkkuuden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Jaa datasetti koulutus- ja validointidataan\n",
    "   Yleinen ensimmäinen askel mallin kouluttamisessa on jakaa datasetti koulutus- ja validointidataan. Tämä mahdollistaa osan datasta käyttämisen mallin kouluttamiseen ja osan mallin testaamiseen. Jos käyttäisit koko dataa mallin kouluttamiseen, sinulla ei olisi keinoa arvioida, kuinka hyvin se todellisuudessa suoriutuisi sellaista dataa vastaan, jota malli ei ole vielä nähnyt. Scikit-learn-kirjaston etuna on se, että se tarjoaa metodin datasetin jakamiseen koulutus- ja testidataan. Lisää ja suorita muistikirjaan seuraava koodi, jolla jaat datan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[['sex','pclass','age','relatives','fare']], data.survived, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Normalisoi syötteet\n",
    "   Seuraavaksi normalisoi syötteet siten, että kaikkia ominaisuuksia käsitellään tasapuolisesti. Esimerkiksi datasetissä ikäarvot vaihtelevat noin 0-100 välillä, kun taas sukupuoli on vain 1 tai 0. Normalisoimalla kaikki muuttujat voit varmistaa, että arvojen vaihteluvälit ovat yhtenevät. Käytä seuraavaa koodia uudessa koodisolussa syötearvojen skaalaamiseksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Valitse, luo ja kouluta algoritmi\n",
    "Koneoppimisalgoritmeja on monia, joista voit valita mallintaaksesi dataa. Scikit-learn-kirjasto tukee monia niistä ja tarjoaa kaavion, joka auttaa valitsemaan oikean algoritmin sinun tilanteeseesi. Tällä kertaa käytä Naïve Bayes -algoritmia, joka on yleinen algoritmi luokitteluongelmiin. Lisää solu, jossa on seuraava koodi, algoritmin luomiseksi ja kouluttamiseksi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Kokeile koulutettua mallia testidatalla\n",
    "\n",
    "Koulutetun mallin avulla voit nyt kokeilla sitä sellaista testidataa vastaan, jota ei käytetty koulutuksessa. Lisää ja suorita seuraava koodi ennustaaksesi testidatan tulokset ja laskeaksesi mallin tarkkuuden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predict_test = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Osa 5 (Valinnainen) Käytä neuroverkkoa\n",
    "\n",
    "Neuroverkko on malli, joka käyttää painotuksia ja aktivointifunktioita, mallintaen ihmisen hermosolujen toimintaa, päätelläkseen lopputuloksen annettujen syötteiden perusteella. Toisin kuin aiemmin käsitellyt koneoppimisalgoritmit, neuroverkot ovat syväoppimisen muoto, jossa sinun ei tarvitse tietää etukäteen ideaalista algoritmia ongelmanratkaisuusi. Niitä voidaan käyttää monissa eri tilanteissa, ja luokittelu on yksi näistä. Tässä osiossa käytät Keras -kirjastoa yhdessä TensorFlow kanssa rakentaaksesi neuroverkon ja tutkiaksesi, kuinka se käsittelee Titanic-datasettiä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuo kirjastot ja luo malli\n",
    "\n",
    "Ensimmäinen askel on tarvittavien kirjastojen tuominen ja mallin luominen. Tässä tapauksessa käytät Sequential -neuroverkkoa, joka on kerroksittainen neuroverkko, jossa useat kerrokset syöttävät tietoa toisiinsa peräkkäin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Luo neuroverkon kerrokset\n",
    "\n",
    "Mallin määrittelyn jälkeen seuraava askel on lisätä neuroverkon kerrokset. Pidetään asiat toistaiseksi yksinkertaisina ja käytetään vain kolmea kerrosta. Lisää seuraava koodi luodaksesi neuroverkon kerrokset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))\n",
    "model.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensimmäisellä kerroksella asetetaan ulottuvuudeksi 5, koska sinulla on viisi syötettä: sukupuoli matkustusluokka, ikä, sukulaiset ja lipun hinta.\n",
    "- Viimeisen kerroksen täytyy tuottaa ulostuloksi 1, koska haluat yksidimensionaalisen ulostulon, joka ilmaisee, selviääkö matkustaja.\n",
    "- Keskimmäinen kerros pidettiin yksinkertaisuuden vuoksi arvossa 5, vaikka se arvo voisi olla erilainen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectified linear unit (relu) -aktivointifunktiota käytetään hyvänä yleisenä aktivointifunktiona kahdessa ensimmäisessä kerroksessa, kun taas sigmoid-aktivointifunktio on tarpeen viimeiselle kerrokselle, koska haluamasi ulostulo (matkustajan selviytyminen tai ei) täytyy skaalata alueelle 0-1 (todennäköisyys matkustajan selviytymiselle).\n",
    "\n",
    "Voit myös tarkastella rakentamasi mallin yhteenvetoa tällä koodirivillä:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Rakenna ja kouluta\n",
    "\n",
    "Kun malli on luotu, se täytyy koota. Osana tätä prosessia sinun täytyy määritellä, millaista optimoijaa käytetään, miten häviö (loss) lasketaan, ja mitä metriikkaa tulisi optimoida. Lisää seuraava koodi mallin rakentamiseksi ja kouluttamiseksi. Huomaat, että koulutuksen jälkeen tarkkuus on noin 61%.\n",
    "\n",
    "Huom: Tämän vaiheen suorittaminen voi kestää koneestasi riippuen muutamasta sekunnista muutamaan minuuttiin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Testaa luotua mallia testidatalla\n",
    "\n",
    "Nyt kun malli on rakennettu ja koulutettu, voimme nähdä, miten se toimii testidataa vastaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(model.predict(X_test).flatten())\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samoin kuin koulutusvaiheessa, huomaat nyt saavuttavasi 79 % tarkkuuden matkustajien selviytymisen ennustamisessa. Käyttäen tätä yksinkertaista neuroverkkoa tulos on parempi kuin aiemmin kokeillun Naive Bayes -luokittelijan 75 % tarkkuus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seuraavat askeleet\n",
    "\n",
    "Nyt kun olet perehtynyt koneoppimisen perusteisiin Visual Studio Code -ympäristössä, tässä on joitain muita Microsoftin resursseja ja opetusohjelmia, joita voit tutkia.\n",
    "\n",
    "- [Data Science profiilimalli](https://code.visualstudio.com/docs/editor/profiles#_data-science-profile-template) – Luo uusi [profiili](https://code.visualstudio.com/docs/editor/profiles), jossa on valikoitu joukko laajennuksia, asetuksia ja koodinpätkiä.\n",
    "- Lue lisää [Jupyter-muistikirjojen käyttämisestä Visual Studio Code -ympäristössä](https://youtu.be/FSdIoJdSnig) (video).\n",
    "- [Aloita Azure Machine Learningin käyttö Visual Studio Code](https://learn.microsoft.com/azure/machine-learning/how-to-setup-vs-code) käyttöönottoa ja mallin optimointia varten hyödyntämällä Azurea.\n",
    "- Löydä lisää tutkittavaa dataa [Azure Open Data Sets](https://azure.microsoft.com/services/open-datasets/) -palvelusta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
